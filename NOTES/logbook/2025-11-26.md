# Work Log

## Redone Lexer

I replaced the entire lexer implementation, and it is FAR more readable!

The idea was to keep taking tokens off the front of the line, one at a time.
Then, we just need some "take one token" functions for the different lexing modes.
The hard part was the recurrence relation.
After all, we can sometimes take _more_ than one token, and that needs to be coordinted in, admittely, an off-putting way.
Still, the main part of the algorithm is just the "single"-token lexers.
It's here that we can see that lookahead is limited (with the propbably workaround-able exception of the multi-line string close delimiter).
We also get to write ordinary text manipulation code, as opposed to the very noisy `streaming` combinators.

In addition to re-implementing what I had, I am now also parsing:
- single-quoted strings
- multi-line strings
- numbers, including digit separators, flaoting point, and alternate bases.

Multi-line strings and numbers are particularly complex.
With the new design, I have relatively little trouble with them.
The thing that brought it together was creating a new number-parsing mode.
I say I'm parsing numbers, but the number tokens aren't yet assembled.
It really means that there are sign,radix,digits,dot tokens.
Just like my idea with assembling strings later, I will assemble numbers later (probably the same phase).

### Future Work

Everything for the new lexer is in `Pipeline`, which I guess throws a bunch of stuff in the same module that should technically be separated.
OTOH, it's a pain to always be switching files, and the abstraction boundaries aren't that easy to accidentally cross.
If, and only when, the lack of separation causes a problem will I separate the pipeline parts.

There are certainly ways to write the lexer's overall pipeline in a way that buffers less data.
The fact is, I'm not sure I care that much about buffering a full line (and re-calculating poositions as I move thought it).
I certainly don't want to use the raw `Streaming (Of a) m r` type, as that led to noisy code.
Instead, I would use something like...

## A New List-like Type

Remember how unary numbers are isomorphic to `List ()`?
Just generalize the `Succ Nat` constructor to `Succ a Nat(a)` (spelled `Cons a List(a)`).
Well, let's also generalize `Zero` to `Zero z`, and spell it `Done z`.
This gives `Linear a z = More a Linear(a, z) | Done z`.
We see that `Linear a ()` is isomorphic to lists.
I implemented this in the `Pipeline` module, along with some less-ordinary `Monad` and whatnot instances.
The basic idea is "let's iterate, and when we get to the end, also give back some extra data".
It neatly avoids a lot of the "tail-recur while accumulating to a buffer, then return a tuple of the fixed-up buffer and whatever other result I need from the iteration" junk I've done.

### Future Work

Submit this data type to the `streaming` package?
Assuming it doesn't already exist.
And really, I'd implemented it as a type synonym, I guess `Linear a r = Stream (Of a) Identity r`.
(And then implement some wrappers for all the combinators.)



