# Work Log

## Common Concrete Syntax (CCS)

I finally decided on "Common Concrete Syntax".
No more weird, opaque names like "eexpr" or "texpr" (or "sexpr" before it).

The name was inspired by the "Common Expression Syntax".
I find that specification very intriguing, and would absolutely use it if I had to implement expressions into a configuration language again.
However, it is limited (very reasonably) to just expressions, and not even lambdas.
For a syntax that is expected to occupy from dozens to thousands of lines per-file, I need something else.

The syntax itself will be mainly algol-based, but incorporate sensitivity to a lot of whitespace.
There's really no reason to not force the statements of a block to be indented and separated by-line.
When the two disagree, that leads to errors, and if the recommendation is to always enforce it in a git hook, then why not enforce it in the parser?
At least that way, a language server will definitely have the tools to provide fixup code actions.

## Prototype Lexer

Over the last couple of days, I wrote a prototype lexer for CCS.
It worked fine, but I'm throwing it away, but I learned some stuff.

I think I'd rather detect the newlines, then parse each line into tokens independently (passing only a little mode state from line to line).
I'm looking forward to not having to write a complex streaming parser for starting the multi-line string.
Likewise, I don't really mind if parsing within a line just takes from the start of an in-memory `Text`, since lines shouldn't be long (if they are, fix your source code).
At the end of the day, I just think the existing code is 

The goal of this lexer was to partition the source code into tokens, applying tags to each section.
Ok ok, partition as in "the locations of the produced tokens cover the entire input".
That means it'd be useful for syntax highlighting.
It also means that the lexer should be a total function from source code to tokens.
If I don't need an error-reporting monad, I don't need the complex types of the streaming library, at least not per-line.
I suspect it'll make the code more idiomatic and much flatter.

I also put some partial documentation of the lexer control flow into the comments as a flowchart.
I came across https://cascii.app for generating ascii/unicoode box-and-line diagrams.
It's pretty nice (I already have ideas on how to improve it, but I will refrain!).

## Source Location Library

I decicided to finally encapsulate and document the location types that I had lying around.
They're in the `source-location` package, though they surely need a bit more work before that's ready for release.
Not much to say, it's pretty simple.

## Audit Script

I wrote an audit script that checks for some possible problems.
It will definitely need a bit more sophistication at some point, but it's already paid off.

At the moment, it:
- looks for various todo tags
- looks for variables that have names marked for their danger
- ensures there aren't any language pragmas hanging around; I'd prefer to have them in the package file according to the idea of "one package, one syntax"

## Lab Book

And ofc I've started this "lab book" where I keep track of my progress as it happens.
This stuff (in `NOTES/labbook`) should never be modified after committed.
Also, it shouldn't be committed until the end of the day.

I've also got a script to edit the current lab book entry.

### Future Work

Start a blog: summarize and present my work periodically, drawing on the content of the lab books.
This would be like a devlog.

Write a script to check on the lab book/devlog:
- are there commits after the last lab book?
- what lab book entries aren't covered by a devlog?

If more people start working on this, I may need to separate the lab books by author.
I think that can be scripted.

I feel like I need a script to help me extract "future work" from these entries.
Or, at least index it so I'm not losing my thoughts.

The README needs to point to the lab book/blog.
That means also having an indexing script that can regenerate a md file with appropriate links.

Throwing this stuff into git hooks would be nice.
I need to remember to actually write this stuff.

# Future Work

## Floating Point Literals

I've read up on IEEE754, and the latest standard specifies both decimal and binary floating point numbers.
Interestingly, it also specifies text formats (in addition to the semantics and binary formats).

Initially, I thought I could do all floating point literals with just a single `FloatingLit Radix Magnitude Exponent` ctor.
This ctor would then translate to a compiletime `Floating` type, and something like a `class IsFloat a where fromFloat :: Floating -> a`, in the vein of Haskell's overloaded literals.
However, just like Haskell's compiletime `Integer` is also available at runtime, surely my `Floating` type would be also.
This raises the disturbing possibility that two floats with different radices might be added, leading to infinite magnitude (eg `0.1 + 0x1.0 :: Floating`).

I think it is reasonable to have two different arbitrary-size floating point literals:
- one for decimal floating points
- one for binary/octal/hexadecimal

The overloaded literal class would look like `class IsFloating a where { fromDecFloat :: DecimalFloating -> a; fromBinFloat :: Floating -> a }`.

This could still risk the `Floating` types to accidentally grow very large (eg `1.0e-1000 + 1.0e1000`).
This could be mitigated by having the `Floating` type hold several disjoint digit strings when there's a big enough gap of zeros.
Still, that's a lot of complexity for a type that may not see much runtime use.
Most arbitrary-precision fp libs have you set the precision of each floating point value (incl results).
A big float library with no precision limits may not be in high-enough demand to rationalize its complexity/danger.

## Comptime Types, Values, and Functions

I'm also thinking about perhaps having a `comptime` quantity associated with variables.
This is slightly different from a `0` (erased) quantity, because while erased variables cannot be used for computation outside types,
    comptime variables could at least be _evaluated_ at compiletime (eg during macro expansion), even in an expression.

So, one possible answer to the fp precision problem above is just to use `comptime`.
Then, we don't even need to support arithmetic on FloatingLit values, since that'd only ever be useful at runtime.
There's also the advantage that comptime expressions must evaluate to something not-comptime
I'm a little excited at the prospect that badly-formed literals will be guaranteed to trigger their parse error at compiletime instead of runtime.

Of course, comptime quantities likely have more applications than just overloaded literals.
Rust has `comptime` as well, and I've heard it can do some nice macro-like stuff.
At the very least, I hope it can reduce the need for macros.

One thing I'm thinking is: if I have comptime figured out, then it might be easy to create a systems language with a few small changes.
The systems language could have full access to a gc at compiletime, but all ordinary data types would be `comptime`.
Then, add in a `layout` declaration to set up the runtime memory layout for types that appear at runtime.

## Syntax Syntax

Let's say we allow backslash-identifier sequences as "holes".
That way, we get named hooles without trying to overload underscore with too much.

Well then, why not name the holes in syntax?
- We'd get to document the parts of the syntax.
- We could assign a grammatical type to each hole, thus allowing syntax to differ in different contexts (term vs do-statement vs decl).
- We could apply a rewrite rule to the hole.
- If I come up with any additional properties to give to holes, then I've got a ready-made space in the concrete syntax to put them.

```
syntax expr:
  if \p then \c else \a -> boolElim:
    "the predicate"
    p: expr
    c: expr -> $(lazy \c)
    a: expr -> $(lazy \a)
```

where `lazy` would be some macro that makes sure the expression evaluation is delayed.
Note that the hole has its mixfixes rewritten before it is inserted into the rewrite rhs.
I've ignored syntax groups (which would get a name, ordering constraints, and the grammar type) above.

